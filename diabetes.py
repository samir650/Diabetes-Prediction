# -*- coding: utf-8 -*-
"""Diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dcX7ktb-LF5J6MT-od2z-Nfs0lEVKn3p

# **Binary Classification Problem**

### import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('ggplot')

from sklearn.preprocessing import scale, StandardScaler,OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import KFold
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
from sklearn.feature_selection import SelectFromModel
from imblearn.pipeline import Pipeline as imbpipeline

import warnings
warnings.filterwarnings('ignore')

Diabetes = pd.read_csv('/content/diabetes.csv')
Diabetes.head()

"""- Attributes Description:
1. Pregnancies: Number of times pregnant
2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test
3. BloodPressure: Diastolic blood pressure (mm Hg)
4. SkinThickness: Triceps skin fold thickness (mm)
5. Insulin: 2-Hour serum insulin (mu U/ml)
6. BMI: Body mass index (weight in kg/(height in m)^2)
7. DiabetesPedigreeFunction: Diabetes pedigree function
8. Age: Age (years)
9. Outcome: Class variable (0 or 1)

# **Data Exploration**
"""

Diabetes.info()

Diabetes.describe()

Diabetes.duplicated().sum()

Diabetes['Pregnancies'].value_counts()

sns.countplot(data = Diabetes ,x='Pregnancies')

"""- insight: The number of pregnancies gradually decreases


"""

sns.histplot(Diabetes['Glucose']).set_title('Glucose Distribution')
plt.show()

"""- insight: Glucose is more distributed between 70 and 80"""

sns.histplot(Diabetes['BloodPressure']).set_title('Blood Pressure Distribution')
plt.show()

"""- insight: Blood pressure is more distributed between 70 and 80 mm Hg"""

sns.histplot(Diabetes['SkinThickness']).set_title('SkinThickness Distribution')
plt.show()

"""- insight: SkinThickness is more distributed between 0 and 50 mm"""

plt.figure(figsize=(15,6))
sns.histplot(Diabetes['Insulin'],binwidth=1).set_title('Insulin Distribution')
plt.show()

"""- insight: Insulin is normal distributed between 0 and 1 mu U/ml"""

sns.histplot(Diabetes['BMI']).set_title('BMI Distribution')
plt.show()

"""- insight: BMI is more distributed between 25 and 40 kg/(height in m)^2

"""

sns.histplot(Diabetes['DiabetesPedigreeFunction']).set_title('Diabetes pedigree function Distribution')
plt.show()

"""- insight: Diabetes pedigree function is more distributed between 0.1 and 0.8

"""

sns.histplot(Diabetes['Age']).set_title('Age Distribution')
plt.show()

"""- insight: Age is more distributed between 22 and 28"""

Diabetes['Outcome'].value_counts()

plt.pie(Diabetes['Outcome'].value_counts() , autopct='%.0f%%', labels=[0,1])
plt.show()

"""- insight: (Does not have diabetes) 0 is more than 1 (have diabetes)

### comparing each feature with the dependent feature
"""

sns.countplot(data=Diabetes, x='Pregnancies', hue='Outcome', palette='viridis')

"""- insight: **After 7 time pregnancies** number of patient has **diabtic is more**"""

plt.figure(figsize=(20,18))
sns.set_style("white")
sns.set_palette("bright")
plt.subplots_adjust(hspace=0.5)
i = 1;
for name in Diabetes.columns:
    plt.subplot(5,2,i)
    sns.histplot(data=Diabetes, x=name, hue="Outcome",kde=True,palette="YlGnBu")
    i = i + 1

"""### summary insights :
- Glucose levels are higher for patients has diabetes
- Insulin levels are higher for patients has diabetes
- Diabetes pedigree function are higher for patients has diabetes
- The older you are, the more likely you are to be positive

### correlation between each attributes
"""

plt.figure(figsize=(8, 8))
heatmap = sns.heatmap(Diabetes.corr(), annot=True,cmap='Oranges',cbar=False)

"""- there is no high correlation between any feature and other

# **Data Preprocessing**

### Split data to train and validation
"""

from sklearn.model_selection import train_test_split

y = Diabetes["Outcome"]
x = Diabetes.drop("Outcome",axis=1)


x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)

sns.pairplot(data = Diabetes)

"""- As shown above, the ratio of the value of zero in the SkinThickness and Insulin features seems to be high. Let's change the corresponding values to the mean value of each feature.

- However, a zero value may be meaningful to the corresponding feature. If you have an expert with expertise in diabetes, you will be able to confirm that your decision is correct. However, since there is no such domain knowledge or friends, we will first replace the corresponding value with the mean value.
"""

zero_to_nan = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']
x_train[zero_to_nan] = x_train[zero_to_nan].replace(0,np.NaN)
x_test[zero_to_nan] = x_test[zero_to_nan].replace(0,np.NaN)

x_train['BloodPressure'] = x_train.groupby('Pregnancies')['BloodPressure'].transform(lambda val : val.fillna(val.median()))
x_train['Glucose'] = x_train.groupby('Pregnancies')['Glucose'].transform(lambda val : val.fillna(val.median()))
x_train['BMI'] = x_train.groupby('Pregnancies')['BMI'].transform(lambda val : val.fillna(val.median()))
x_train['SkinThickness'] = x_train.groupby('Pregnancies')['SkinThickness'].transform(lambda val : val.fillna(val.median()))
x_train['Insulin'] = x_train.groupby('Pregnancies')['Insulin'].transform(lambda val : val.fillna(val.median()))
x_train['Insulin'] = x_train.groupby('Age')['Insulin'].transform(lambda val : val.fillna(val.median()))

x_test['BloodPressure'] = x_test.groupby('Pregnancies')['BloodPressure'].transform(lambda val : val.fillna(val.median()))
x_test['Glucose'] = x_test.groupby('Pregnancies')['Glucose'].transform(lambda val : val.fillna(val.median()))
x_test['BMI'] = x_test.groupby('Pregnancies')['BMI'].transform(lambda val : val.fillna(val.median()))
x_test['SkinThickness'] = x_test.groupby('Pregnancies')['SkinThickness'].transform(lambda val : val.fillna(val.median()))
x_test['Insulin'] = x_test.groupby('Pregnancies')['Insulin'].transform(lambda val : val.fillna(val.median()))
x_test['Insulin'] = x_test.groupby('Age')['Insulin'].transform(lambda val : val.fillna(val.median()))

"""### over sampling"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=0)
x_train , y_train = smote.fit_resample(x_train,y_train)

x_train.shape,y_train.shape

"""### create new features"""

# According to BMI, some ranges were determined and categorical variables were assigned.
def set_BMI(row):
    if row["BMI"] < 18.5:
        return "Underweight"
    elif row["BMI"] > 18.5 and row["BMI"] <= 24.9:
        return "Normal"
    elif row["BMI"] > 24.9 and row["BMI"] <= 29.9:
        return "Overweight"
    elif row["BMI"] > 29.9 and row["BMI"] <= 34.9:
        return "Obesity 1"
    elif row["BMI"] > 34.9 and row["BMI"] <= 39.9:
        return "Obesity 2"
    else:
        return "Obesity 3"

x_train["NewBMI"] = x_train.apply(set_BMI, axis=1)
x_test["NewBMI"] = x_test.apply(set_BMI, axis=1)

x_train.head()

def set_insulin(row):
    if row["Insulin"] >= 16 and row["Insulin"] <= 166:
        return "Normal"
    else:
        return "Abnormal"

x_train["NewInsulinScore"] = x_train.apply(set_insulin, axis=1)
x_test["NewInsulinScore"] = x_test.apply(set_insulin, axis=1)

x_train.head()

def set_Glucose(row):
    if row["Glucose"] < 140:
        return "Normal"
    elif row["Glucose"] >= 140 and row["Glucose"] <= 199:
        return "prediabetes"
    else:
        return "High"

x_train["NewGlucose"] = x_train.apply(set_Glucose, axis=1)
x_test["NewGlucose"] = x_test.apply(set_Glucose, axis=1)

x_train.head()

"""### One Hot Encoding"""

x_train = pd.get_dummies(x_train, columns =["NewBMI","NewInsulinScore", "NewGlucose"], drop_first = True)
x_test = pd.get_dummies(x_test, columns =["NewBMI","NewInsulinScore", "NewGlucose"], drop_first = True)
x_test.head()

x_test.reset_index(inplace = True)
x_test.drop('index',axis=1,inplace=True)
x_test

"""###handling outliers using (Log Transformation & Winsorizing)

"""

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))

x_train.loc[:,'Pregnancies':'Age'].boxplot(ax=axes[0])
axes[0].set_title('x_train Distribution')

x_test.loc[:,'Pregnancies':'Age'].boxplot(ax=axes[1])
axes[1].set_title('x_test Distribution')

plt.tight_layout()
plt.show()

from scipy.stats.mstats import winsorize

for column_name in x_train.columns[:8]:

  x_train[column_name] = np.log1p(x_train[column_name])
  x_train[column_name] = winsorize(x_train[column_name], limits=[0.05, 0.05])

  x_test[column_name] = np.log1p(x_test[column_name])
  x_test[column_name] = winsorize(x_test[column_name], limits=[0.05, 0.05])

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))

x_train.loc[:,'Pregnancies':'Age'].boxplot(ax=axes[0])
axes[0].set_title('x_train Distribution')

x_test.loc[:,'Pregnancies':'Age'].boxplot(ax=axes[1])
axes[1].set_title('x_test Distribution')

plt.tight_layout()
plt.show()

"""# **Build Model**"""

models = []
models.append(('KNN', KNeighborsClassifier()))
models.append(('RF', RandomForestClassifier(random_state = 12345)))
models.append(('XGB', GradientBoostingClassifier(random_state = 12345)))
models.append(("LightGBM", LGBMClassifier(random_state = 12345)))
models.append(("BC", BaggingClassifier(random_state = 12345)))
models.append(("EX_Trees", ExtraTreesClassifier(random_state = 12345)))

# evaluate each model in turn
results = []
names = []

for name, model in models:

        kfold = KFold(n_splits = 10)

        cv_results = cross_val_score(model, x_train, y_train, cv = 10, scoring= "accuracy")
        results.append(cv_results)
        names.append(name)
        msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
        print(msg)

# boxplot algorithm comparison
fig = plt.figure(figsize=(15,10))
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

"""###LGBMClassifier"""

LGBM_model = LGBMClassifier()
LGBM_model.fit(x_train,y_train)
y_pred = LGBM_model.predict(x_test)

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
f1score=f1_score(y_test,y_pred)

accuracy,recall,precision,f1score

from sklearn.metrics import confusion_matrix
Confusion_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(Confusion_matrix,annot=True)

"""### Random Forest Classifier model"""

from sklearn.ensemble import RandomForestClassifier
RD_model = RandomForestClassifier()
RD_model.fit(x_train,y_train)
y_pred = RD_model.predict(x_test)

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
f1score=f1_score(y_test,y_pred)

accuracy,recall,precision,f1score

from sklearn.metrics import confusion_matrix
Confusion_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(Confusion_matrix,annot=True)

"""### BaggingClassifier"""

from sklearn.ensemble import BaggingClassifier
BG_model = BaggingClassifier()
BG_model.fit(x_train,y_train)
y_pred = BG_model.predict(x_test)

from sklearn.metrics import confusion_matrix
Confusion_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(Confusion_matrix,annot=True)

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
f1score=f1_score(y_test,y_pred)

accuracy,recall,precision,f1score

"""### Extra Trees Classifier"""

from sklearn.ensemble import ExtraTreesClassifier

EX_model = ExtraTreesClassifier()
EX_model.fit(x_train,y_train)
y_pred = EX_model.predict(x_test)

from sklearn.metrics import confusion_matrix
Confusion_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(Confusion_matrix,annot=True)

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
f1score=f1_score(y_test,y_pred)

accuracy,recall,precision,f1score

"""# Hyperparameter Tuning"""

!pip install --quiet optuna
import optuna

def objective(trial):
    # Define the hyperparameter search space
    n_estimators = trial.suggest_int('n_estimators', 50, 200)
    random_state = trial.suggest_int('random_state', 1, 200)
    max_depth = trial.suggest_int('max_depth', 5, 30)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)
    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])

    # Create and train the Random Forest model with the suggested hyperparameters
    rf_model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        max_features=max_features,
        random_state=random_state
    )
    rf_model.fit(x_train, y_train)

    # Predict on the test set
    y_pred = rf_model.predict(x_test)

    # Evaluate accuracy
    accuracy = accuracy_score(y_test, y_pred)

    return accuracy

# Set up the Optuna study
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=20)

# Get the best hyperparameters
best_params = study.best_params
print("Best Hyperparameters:", best_params)

# Train the model with the best hyperparameters
best_rf_model = RandomForestClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    min_samples_split=best_params['min_samples_split'],
    min_samples_leaf=best_params['min_samples_leaf'],
    max_features=best_params['max_features'],
    random_state=42
)
best_rf_model.fit(x_train, y_train)

# Predict on the test set
y_pred = best_rf_model.predict(x_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy on Test Set:", accuracy)

"""# **Best Model With Best Hyperparameter**"""

rf_model = RandomForestClassifier(
        n_estimators=112,
        max_depth=18,
        min_samples_split=3,
        min_samples_leaf=1,
        max_features='sqrt',
        random_state=133
    )
rf_model.fit(x_train, y_train)
y_pred = rf_model.predict(x_test)

from sklearn.metrics import confusion_matrix
Confusion_matrix = confusion_matrix(y_test,y_pred)
sns.heatmap(Confusion_matrix,annot=True,cmap='Blues')

from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
accuracy=accuracy_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
f1score=f1_score(y_test,y_pred)

accuracy,recall,precision,f1score

"""### creating Pipelines"""

from imblearn.pipeline import make_pipeline

numeric_features = x_train.loc[:,'Pregnancies':'Age'].columns

preprocessor = ColumnTransformer(
    transformers=[
        ('numeric', Pipeline([
            ('impute', SimpleImputer(strategy='median')),
            ('log_transform', FunctionTransformer(np.log1p, validate=False)),
            ('winsorize', FunctionTransformer(lambda x: winsorize(x, limits=[0.01, 0.01]), validate=False))
        ]), numeric_features)
    ],
    remainder='passthrough'
)


# Create a pipeline with preprocessing and Random Forest classifier
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        n_estimators=112,
        max_depth=18,
        min_samples_split=3,
        min_samples_leaf=1,
        max_features='sqrt',
        random_state=133
    ))
])

# Train the pipeline
pipeline.fit(x_train, y_train)

# Make predictions on the test set
y_pred = pipeline.predict(x_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

"""### Saving The Model"""

import joblib

# Save the model
joblib.dump(rf_model, 'rf_model.joblib')

# Load the model
loaded_model = joblib.load('rf_model.joblib')